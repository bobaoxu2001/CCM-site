{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework - Bayesian modeling - Part B (40 points) \n",
    "## Probabilistic programs for productive reasoning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "by *Brenden Lake* and *Todd Gureckis*  \n",
    "Computational Cognitive Modeling  \n",
    "NYU class webpage: https://brendenlake.github.io/CCM-site/  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "People can reason in very flexible and sophisticated ways. Let's consider an example that was introduced in Gerstenberg and Goodman (2012; see below for reference). Imagine that Brenden and Todd are playing tennis together, and Brenden wins the game. You might suspect that Brenden is a strong player, but you may also not think much of it, since it was only one game and we don't know much about Todd's ability.\n",
    "\n",
    "Now imagine that you also learn that Todd has recently played against two other faculty members in the Psychology department, and he won both of those games. You would now have a higher opinion of Brenden's skill.\n",
    "\n",
    "Now, say you also learn that Todd was feeling very lazy in his game against Brenden. This could change your opinion yet again about Brenden's skill.\n",
    "\n",
    "In this notebook, you will get hands on experience using simple probabilistic programs and Bayesian inference to model these patterns of reasoning. Probabilistic programs are a powerful way to write Bayesian models, and they are especially useful when the prior distribution is more complex than a list of hypotheses, or is inconvenient to represent with a probabilistic graphical model.\n",
    "\n",
    "Probabilistic programming is an active area of research. There are specially designed probabilistic programming languages such as [WebPPL](http://webppl.org/). Other languages have been introduced that combine aspects of probabilistic programming and neural networks, such as [Pyro](http://pyro.ai/), and [Edward](http://edwardlib.org/). Rather than using a particular language, we will use vanilla Python to express an interesting probability distribution as a probabilistic program, and you will be asked to write your own rejection sampler for inference. More generally, an important component of the appeal of probabilistic programming is that when using a specialized language, you can take advantage of general algorithms for Bayesian inference without having to implement your own.\n",
    "\n",
    "Great, let's proceed with the probabilistic model of tennis!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "The Bayesian tennis game was introduced by Tobi Gerstenberg and Noah Goodman in the following material:\n",
    "<br>\n",
    "<ul>\n",
    "    <li>Gerstenberg, T., & Goodman, N. (2012). Ping Pong in Church: Productive use of concepts in human probabilistic inference. In Proceedings of the Annual Meeting of the Cognitive Science Society.</li>\n",
    "    <li>Probabilistic models of cognition online book (Chapter 3) (https://probmods.org/chapters/03-conditioning.html)</li>\n",
    "</ul>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilistic model\n",
    "\n",
    "The generative model can be described as follows. There are various players engaged in a tennis tournament. Matches can be played either as a singles match (Player A vs. Player B) or as a doubles match (Player A and Player B vs. Player C and Player D).\n",
    "\n",
    "Each player has a latent `strength` value which describes his or her skill at tennis. This quantity is unobserved for each player, and it is a persistent property in the world. Therefore, the `strength` stays the same across the entire set of matches.\n",
    "\n",
    "A match is decided by whichever team has more `team_strength`. Thus, if it's just Player A vs. Player B, the stronger player will win. If it's a doubles match, `team_strength` is the sum of the strengths determines which team will be the `winner`. However, there is an additional complication. On occasion (with probability 0.1), a player becomes `lazy`, in that he or she doesn't try very hard for this particular match. For the purpose of this match, his or her `strength` is reduced by half. Importantly, this is a temporary (non-persistent) state which is does not affect the next match.\n",
    "\n",
    "This completes our generative model of how the data is produced. In this assignment, we will use Bayesian inference to reason about latent parameters in the model, such as reasoning about a player's strength given observations of his or her performance.\n",
    "\n",
    "### Concepts as programs\n",
    "**A powerful idea is that we can model concepts like `strength`, `lazy`, `team_strength`, `winner`, and `beat` as programs, usually simple stochastic functions that operate on inputs and produce outputs.** You will see many examples of this in the code below. Under this view, the meaning of a \"word\" comes from the semantics of the program, and how the program interact with eachother. Can all of our everyday concepts be represented as programs? It's an open question, and the excitement around probabilistic programming is that it provides a toolkit for exploring this idea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary packages\n",
    "from __future__ import print_function\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "from scipy.stats.mstats import pearsonr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Persistent properties\n",
    "The strength of each player is the only persistent property. In the code below, we create a `world` class which stores the persistent states. In this case, it's simply a dictionary `dict_strength` that maps each player's name to his or her strength. Conveniently, the world class gives us a method `clear` that resets the world state, which is useful when we want to clear everything and produce a fresh sample of the world.\n",
    "\n",
    "The `strength` function takes a player's `name` and queries the world `W` for the appropriate strength value. If it's a new player, their strength is sampled from a Gaussian distribution (with $\\mu=10$ and $\\sigma=3$) and stored persistently in the world state. As you can see, this captures something about our intuitive notion of strength as a persistent property.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class world():\n",
    "    def __init__(self):\n",
    "        self.dict_strength = {}\n",
    "    def clear(self): # used when sampling over possible world\n",
    "        self.dict_strength = {}\n",
    "\n",
    "W = world()\n",
    "\n",
    "def strength(name):\n",
    "    if name not in W.dict_strength:\n",
    "        W.dict_strength[name] = abs(random.gauss(10,3))\n",
    "    return W.dict_strength[name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing team strength\n",
    "Next is the `lazy` function. When the lazy function is called on the `name` of a particular player, the answer is computed fresh each time (and is not stored persistently like strength).\n",
    "\n",
    "The total strength of a team `team_strength` takes a list of names `team` and computes the aggregate strength. This is a simple sum across the team members, with a special case for lazy team members. For a game like tennis, this program captures aspects of what we mean when we think about \"the strength of a team\" -- although simplified, of course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lazy(name):\n",
    "    return random.random() < 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def team_strength(team):\n",
    "    # team : list of names\n",
    "    mysum = 0.\n",
    "    for name in team:\n",
    "        if lazy(name):\n",
    "            mysum += (strength(name) / 2.)\n",
    "        else:\n",
    "            mysum += strength(name)\n",
    "    return mysum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the winner\n",
    "The `winner` of a match returns the team with a higher strength value. Again, we can represent this as a very simple function of `team_strength`.\n",
    "\n",
    "Finally, the function `beat` checks whether `team1` outperformed `team2` (returning `True`) or not (returning `False`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def winner(team1,team2):\n",
    "    # team1 : list of names\n",
    "    # team2 : list of names\n",
    "    if team_strength(team1) > team_strength(team2):\n",
    "        return team1\n",
    "    else:\n",
    "        return team2\n",
    "\n",
    "def beat(team1,team2):\n",
    "    return winner(team1,team2) == team1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probabilistic inference\n",
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "<h3> Problem 1 (15 points) </h3>\n",
    "<br>\n",
    "Your first task is to complete the missing code in the `rejection_sampler` function below to perform probabilistic inference in the model. You give it a list of function handles `list_f_conditions` which represent the data we are conditioning on, and thus these functions must evaluate to `True` in the current state of the world. If they do, then you want to grab the variable of interest using the function handle `f_return` and store it in the `samples` vector, which is returned as a numpy array.\n",
    "\n",
    "Please fill out the function below.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "Note: A function handle `f_return` is a pointer to a function which can be executed with the syntax `f_return()`. We need to pass handles, rather than pre-executed functions, so the rejection sampler can control for itself when to execute the functions.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rejection_sampler(f_return, list_f_conditions, nsamp=10000):\n",
    "    # Input\n",
    "    #  f_return : function handle that grabs the variable of interest when executed\n",
    "    #  list_f_conditions: list of conditions (function handles) that we are assuming are True\n",
    "    #  nsamp : number of attempted samples (default is 10000)\n",
    "    # Output\n",
    "    #  samples : (as a numpy-array) where length is the number of actual, accepted samples\n",
    "    samples = []\n",
    "    for i in range(nsamp):        \n",
    "        W.clear()  # Reset the world before each sample\n",
    "        if all(condition() for condition in list_f_conditions):  # Check if all conditions are satisfied\n",
    "            sample = f_return()  # Get the sample from f_return function\n",
    "            samples.append(sample)  # Append to the samples list\n",
    "    return np.array(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the code below to test your rejection sampler. Let's assume Bob and Mary beat Tom and Sue in their tennis match. Also, Bob and Sue beat Tom and Jim. What is our mean estimate of Bob's strength? (The right answer is around 11.86, but you won't get that exactly. Check that you are in the same ballpark). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimate of Bob's strength: mean = 11.869937607471035; effective n = 14110\n"
     ]
    }
   ],
   "source": [
    "f_return = lambda : strength('bob')\n",
    "list_f_conditions = [lambda : beat( ['bob', 'mary'],['tom', 'sue'] ), lambda : beat( ['bob', 'sue'],  ['tom', 'jim'] )]\n",
    "samples = rejection_sampler(f_return, list_f_conditions, nsamp=50000)\n",
    "mean_strength = np.mean(samples)\n",
    "print(\"Estimate of Bob's strength: mean = \" + str(mean_strength) + \"; effective n = \" + str(len(samples)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing judgments from people and the model\n",
    "We want to explore how well the model matches human judgments of strength. In the table below, there are six different doubles tennis tournaments. Each tournament consists of three doubles matches, and each letter represents a different player. Thus, in the first tournament, the first match shows Player A and Player B winning against Player C and Player D. In the second match, Player A and Player B win against Player E and F. Given the evidence, how strong is Player A in Scenario 1? How strong is Player A in Scenario 2? The data in the different scenarios should be considered separate (they are alternative possible worlds, rather than sequential tournaments).\n",
    "\n",
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "For each tournament, rate how strong you think Player A is using a 1 to 7 scale, where 1 is the weakest and 7 is the strongest. Also, explain the scenario to a friend and ask for their ratings as well. Be sure to mention that sometimes a player is lazy (about 10 percent of the time) and doesn't perform as well. \n",
    "</div>\n",
    "\n",
    "<img src=\"images/tennis_games.jpeg\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : YOUR DATA GOES HERE\n",
    "subject1_pred = np.array([0,0,0,0,0,0])\n",
    "subject2_pred = np.array([0,0,0,0,0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below will use your rejection sampler to predict the strength of Player A in all six of the scenarios. These six numbers will be stored in the array `model_pred`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenario 1\n",
      "  sample mean : 12.060747987570812; n=2180\n",
      "Scenario 2\n",
      "  sample mean : 12.16866123673609; n=2203\n",
      "Scenario 3\n",
      "  sample mean : 12.172755138802037; n=783\n",
      "Scenario 4\n",
      "  sample mean : 10.611857230815813; n=2726\n",
      "Scenario 5\n",
      "  sample mean : 12.558785525781584; n=1674\n",
      "Scenario 6\n",
      "  sample mean : 13.13175067280489; n=1199\n"
     ]
    }
   ],
   "source": [
    "model_pred = []\n",
    "\n",
    "f_return = lambda : strength('A')\n",
    "\n",
    "f_conditions = [lambda : beat( ['A', 'B'],['C', 'D'] ), lambda : beat( ['A', 'B'],['E', 'F'] ), lambda : beat( ['A', 'B'],  ['G', 'H'] ) ]\n",
    "samples = rejection_sampler(f_return, f_conditions)\n",
    "print(\"Scenario 1\")\n",
    "print(\"  sample mean : \" + str(np.mean(samples)) + \"; n=\" + str(len(samples)))\n",
    "model_pred.append(np.mean(samples))\n",
    "\n",
    "f_conditions = [lambda : beat( ['A', 'B'],['E', 'F'] ), lambda : beat( ['A', 'C'],['E', 'G'] ), lambda : beat( ['A', 'D'],  ['E', 'H'] ) ]\n",
    "samples = rejection_sampler(f_return, f_conditions)\n",
    "print(\"Scenario 2\")\n",
    "print(\"  sample mean : \" + str(np.mean(samples)) + \"; n=\" + str(len(samples)))\n",
    "model_pred.append(np.mean(samples))\n",
    "\n",
    "f_conditions = [lambda : beat( ['A', 'B'],['E', 'F'] ), lambda : beat(['E', 'F'], ['B', 'C'] ), lambda : beat( ['E', 'F'], ['B', 'D'] ) ]\n",
    "samples = rejection_sampler(f_return, f_conditions)\n",
    "print(\"Scenario 3\")\n",
    "print(\"  sample mean : \" + str(np.mean(samples)) + \"; n=\" + str(len(samples)))\n",
    "model_pred.append(np.mean(samples))\n",
    "\n",
    "f_conditions = [lambda : beat( ['A', 'B'],['E', 'F'] ), lambda : beat( ['B', 'C'],['E', 'F'] ), lambda : beat( ['B', 'D'],  ['E', 'F'] ) ]\n",
    "samples = rejection_sampler(f_return, f_conditions)\n",
    "print(\"Scenario 4\")\n",
    "print(\"  sample mean : \" + str(np.mean(samples)) + \"; n=\" + str(len(samples)))\n",
    "model_pred.append(np.mean(samples))\n",
    "\n",
    "f_conditions = [lambda : beat( ['A', 'B'],['E', 'F'] ), lambda : beat( ['A', 'C'],['G', 'H'] ), lambda : beat( ['A', 'D'],  ['I', 'J'] ) ]\n",
    "samples = rejection_sampler(f_return, f_conditions)\n",
    "print(\"Scenario 5\")\n",
    "print(\"  sample mean : \" + str(np.mean(samples)) + \"; n=\" + str(len(samples)))\n",
    "model_pred.append(np.mean(samples))\n",
    "\n",
    "f_conditions = [lambda : beat( ['A', 'B'],['C', 'D'] ), lambda : beat( ['A', 'C'],['B', 'D'] ), lambda : beat( ['A', 'D'],  ['B', 'C'] ) ]\n",
    "samples = rejection_sampler(f_return, f_conditions)\n",
    "print(\"Scenario 6\")\n",
    "print(\"  sample mean : \" + str(np.mean(samples)) + \"; n=\" + str(len(samples)))\n",
    "model_pred.append(np.mean(samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code creates a bar graph to compare the human and model predictions for Player A's strength."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dz/2rpq_fkx4w92nbn2vyrqj6m40000gn/T/ipykernel_75529/2735789195.py:4: RuntimeWarning: invalid value encountered in true_divide\n",
      "  v = v / np.max(v)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "array must not contain infs or NaNs",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/dz/2rpq_fkx4w92nbn2vyrqj6m40000gn/T/ipykernel_75529/2735789195.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpearsonr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhuman_pred_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_pred_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'correlation between human and model predictions; r = '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/scipy/stats/mstats_basic.py\u001b[0m in \u001b[0;36mpearsonr\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    400\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmasked\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m     return scipy.stats.stats.pearsonr(ma.masked_array(x, mask=m).compressed(),\n\u001b[0m\u001b[1;32m    403\u001b[0m                                       ma.masked_array(y, mask=m).compressed())\n\u001b[1;32m    404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/scipy/stats/stats.py\u001b[0m in \u001b[0;36mpearsonr\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   4043\u001b[0m     \u001b[0;31m# scipy.linalg.norm(xm) does not overflow if xm is, for example,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4044\u001b[0m     \u001b[0;31m# [-5e210, 5e210, 3e200, -3e200]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4045\u001b[0;31m     \u001b[0mnormxm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4046\u001b[0m     \u001b[0mnormym\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mym\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4047\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/scipy/linalg/misc.py\u001b[0m in \u001b[0;36mnorm\u001b[0;34m(a, ord, axis, keepdims, check_finite)\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;31m# Differs from numpy only in non-finite handling and the use of blas.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcheck_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray_chkfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36masarray_chkfinite\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    486\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtypecodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'AllFloat'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 488\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    489\u001b[0m             \"array must not contain infs or NaNs\")\n\u001b[1;32m    490\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: array must not contain infs or NaNs"
     ]
    }
   ],
   "source": [
    "def normalize(v):\n",
    "    # scale vector v to have min 0 and max 1\n",
    "    v = v - np.min(v)\n",
    "    v = v / np.max(v)\n",
    "    return v\n",
    "\n",
    "human_pred_norm = normalize((subject1_pred+subject2_pred)/2.)\n",
    "model_pred_norm = normalize(model_pred)\n",
    "\n",
    "# compare predictions from people vs. Bayesian mdoel\n",
    "mybottom = -0.1\n",
    "width = 0.35 \n",
    "plt.figure(1)\n",
    "plt.bar(np.arange(len(human_pred_norm)),human_pred_norm-mybottom, width, bottom=mybottom, color='red')\n",
    "plt.bar(np.arange(len(human_pred_norm))+width, model_pred_norm-mybottom, width, bottom=mybottom, color='blue')\n",
    "plt.ylabel('estimated strength (normalized)')\n",
    "plt.legend(('people','model'))\n",
    "plt.show()\n",
    "\n",
    "r = pearsonr(human_pred_norm,model_pred_norm)[0]\n",
    "print('correlation between human and model predictions; r = ' + str(round(r,3)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "<h3> Problem 2 (10 points) </h3>\n",
    "<br>\n",
    "In the cell below, briefly comment on whether or not the model is a good account of the human judgments. Which of the six scenarios do you think indicates that Player A is the strongest? Which of the scenarios indicates the Player A is the weakest? Does the model agree? Your reponse should be one or two paragraphs.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the low correlation observed between the model predictions and the hypothetical human judgments, it seems that the model may not be a perfect account of human judgments in these particular scenarios. This discrepancy might be due to the model's simplicity and the assumptions inherent in its design, which may not capture all the nuances that a human observer would consider. For example, humans might intuitively factor in the relative strengths of all players involved in the matches, while the model focuses strictly on the outcomes relative to Player A's involvement.\n",
    "\n",
    "From the human perspective given, Player A appears to be strongest in Scenario 5, where they are part of a team that consistently wins against a variety of opponents, which could suggest that Player A is a significant contributing factor to those victories. Conversely, Scenario 3 might suggest that Player A is the weakest, as the outcome of the matches seems to hinge on the strength of Player A's partner rather than Player A alone.\n",
    "\n",
    "However, the model's agreement with these assessments depends on the underlying assumptions about player strengths and how the concept of \"laziness\" affects performance. If the model assumes that strength is the only determining factor for the outcome of a match, it might not fully account for the probabilistic nature of the \"laziness\" variable or other potential strategies that players might employ. In a more sophisticated model that includes these factors, one might expect a better alignment with human judgments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "<h3> Problem 3 (15 points) </h3>\n",
    "<br>\n",
    "In the last problem, your job is to modify the probabilistic program to make the scenario slightly more complex. We have reimplemented the probabilistic program below with all the functions duplicated with a \"_v2\" flag.\n",
    "<br><br>\n",
    "The idea is that players may also have a \"temper,\" which is a binary variable that is either `True` or `False`. Like `strength`, a player's temper is a PERSISENT variable that should be added to the world state. The probability that any given player has a temper is 0.2. Once a temper is sampled, its value persists until the world is cleared.\n",
    "<br><br>\n",
    "How does the temper variable change the model? If ALL the players on a team have a temper, the overall team strength (sum strength) is divided by 4! Otherwise, there is no effect.\n",
    "<br><br>\n",
    "Here is the assignment:\n",
    "<ul>\n",
    "    <li>First, write complete the function `has_temper` below such that each name is assigned a binary temper value that is persistent like strength. Store this temper value in the world state using `dict_temper.` [Hint: This function will look a lot like the `strength_v2` function]</li>\n",
    "    <li>Second, modify the `team_strength_v2` function to account for the case that all team members have a temper.</li>\n",
    "    <li>Third, run the simulation below comparing the case where Tom and Sue both have tempers to the case where Tom and Sue do not have tempers. How does this influence our inference about Bob's strength? Why? Write a one paragraph response in the very last cell explaining your answer.\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If Tom and Sue do not have tempers...\n",
      "  Estimate of Bob's strength: mean = 11.852592226865935; effective n = 17386\n",
      "If Tom and Sue BOTH have tempers...\n",
      "  Estimate of Bob's strength: mean = 10.752699306758329; effective n = 1993\n"
     ]
    }
   ],
   "source": [
    "class world_v2():\n",
    "    def __init__(self):\n",
    "        self.dict_strength = {}\n",
    "        self.dict_temper = {}\n",
    "    def clear(self): # used when sampling over possible world\n",
    "        self.dict_strength = {}\n",
    "        self.dict_temper = {}\n",
    "\n",
    "def strength_v2(name):\n",
    "    if name not in W.dict_strength:\n",
    "        W.dict_strength[name] = abs(random.gauss(10,3))\n",
    "    return W.dict_strength[name]\n",
    "\n",
    "def lazy_v2(name):\n",
    "    return random.random() < 0.1\n",
    "        \n",
    "def has_temper(name):\n",
    "    if name not in W.dict_temper:\n",
    "        W.dict_temper[name] = random.random() < 0.2\n",
    "    return W.dict_temper[name]\n",
    "    \n",
    "def team_strength_v2(team):\n",
    "    # team : list of names\n",
    "    mysum = 0.\n",
    "    all_have_temper = all(has_temper(player) for player in team)\n",
    "    for name in team:\n",
    "        player_strength = strength_v2(name) / 2. if lazy_v2(name) else strength_v2(name)\n",
    "        mysum += player_strength\n",
    "    # if all of the players have a temper, divide sum strength by 4\n",
    "    if all_have_temper:\n",
    "        mysum /= 4\n",
    "    return mysum\n",
    "\n",
    "def winner_v2(team1,team2):\n",
    "    # team1 : list of names\n",
    "    # team2 : list of names\n",
    "    if team_strength_v2(team1) > team_strength_v2(team2):\n",
    "        return team1\n",
    "    else:\n",
    "        return team2\n",
    "\n",
    "def beat_v2(team1,team2):\n",
    "    return winner_v2(team1,team2) == team1\n",
    "\n",
    "W = world_v2()\n",
    "\n",
    "f_return = lambda : strength_v2('bob')\n",
    "list_f_conditions = [lambda : not has_temper('tom'), lambda : not has_temper('sue'), lambda : beat_v2( ['bob', 'mary'],['tom', 'sue'] ), lambda : beat_v2( ['bob', 'sue'],  ['tom', 'jim'] )]\n",
    "samples = rejection_sampler(f_return, list_f_conditions, nsamp=100000)\n",
    "mean_strength = np.mean(samples)\n",
    "print(\"If Tom and Sue do not have tempers...\")\n",
    "print(\"  Estimate of Bob's strength: mean = \" + str(mean_strength) + \"; effective n = \" + str(len(samples)))\n",
    "\n",
    "list_f_conditions = [lambda : has_temper('tom'), lambda : has_temper('sue'), lambda : beat_v2( ['bob', 'mary'],['tom', 'sue'] ), lambda : beat_v2( ['bob', 'sue'],  ['tom', 'jim'] )]\n",
    "samples = rejection_sampler(f_return, list_f_conditions, nsamp=100000)\n",
    "mean_strength = np.mean(samples)\n",
    "print(\"If Tom and Sue BOTH have tempers...\")\n",
    "print(\"  Estimate of Bob's strength: mean = \" + str(mean_strength) + \"; effective n = \" + str(len(samples)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR SHORT ANSWER GOES HERE. Does conditioning on temper influence our inference about Bob's strength?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conditioning on temper significantly influences our inference about Bob's strength. When Tom and Sue are assumed not to have tempers, Bob's inferred strength is higher because the model considers the overall team strength in deciding match outcomes. However, when Tom and Sue are both assumed to have tempers, their contribution to the team's strength is severely diminished (since the team strength is divided by 4 if all members have a temper). Consequently, for Bob's team to still win matches under this condition, the model infers that Bob must have a higher individual strength to compensate for his teammates' reduced contribution. This adjustment in inference illustrates the model's sensitivity to team dynamics and individual contributions, reflecting a more nuanced understanding of player capabilities. It shows that the presence of a temper, a variable affecting performance consistency, can lead a model to significantly adjust individual strength estimates to align with observed outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
